{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cs7641assn4 as a4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 35)\n",
    "# pd.reset_option(\"display.max_columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rH = -1 #-5 # reward for H(ole)\n",
    "rG = 1 # 10 # reward for G(oal)\n",
    "rF = -0.2# reward includes S(tart) and F(rozen)\n",
    "size = 4 # height and width of square gridworld, [4, 8, 16] are included in cs7641assn4.py \n",
    "p = 0.8 # if generating a random map probability that a grid will be F(rozen)\n",
    "map_name = 'x'.join([str(size)]*2) # None, if you want a random map\n",
    "desc = a4.MAPS[map_name] # None, if you want a random map\n",
    "is_slippery = False\n",
    "\n",
    "\n",
    "epsilon = 1e-8 # convergence threshold for policy/value iteration\n",
    "gamma = 0.8 # discount parameter for past policy/value iterations\n",
    "max_iter = 10000 # maximum iterations for slowly converging policy/value iteration \n",
    "\n",
    "# Qlearning(env, rH=0, rG=1, rF=0, qepsilon=0.1, lr=0.8, gamma=0.95, episodes=10000)\n",
    "qepsilon = 0.1 # epsilon value for the Q-learning epsilon greedy strategy\n",
    "lr = 0.8 # Q-learning rate\n",
    "qgamma = 0.95 # Q-Learning discount factor\n",
    "episodes = 10000 # number of Q-learning episodes\n",
    "initial = 0 # value to initialize the Q grid\n",
    "decay = True\n",
    "\n",
    "# Printing options\n",
    "report = True # For cs7641assn4.py policy and value iteration functions\n",
    "display_print = True # For this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Board--\n",
      "\n",
      "\u001b[41mS\u001b[0m  F  F  F\n",
      "F  H  F  H\n",
      "F  F  F  H\n",
      "H  F  F  G\n",
      "\n",
      "--Actions for Position to the Left of the Goal--\n",
      "{0: [(1.0, 13, -0.2, False)],\n",
      " 1: [(1.0, 14, -0.2, False)],\n",
      " 2: [(1.0, 15, 1, True)],\n",
      " 3: [(1.0, 10, -0.2, False)]}\n",
      "\n",
      "--Reward Values at Each State--\n",
      "-0.2  -0.2  -0.2  -0.2  \n",
      "-0.2    -1  -0.2    -1  \n",
      "-0.2  -0.2  -0.2    -1  \n",
      "  -1  -0.2  -0.2     1  \n"
     ]
    }
   ],
   "source": [
    "# Create Environment\n",
    "env = a4.getEnv(env_id='hw4-FrozenLake-v0', rH=rH, rG=rG, rF=rF, \n",
    "                desc=desc,  \n",
    "                is_slippery=is_slippery, render_initial=True)\n",
    "\n",
    "# Store a representation of the map\n",
    "env_desc = env.desc.astype('<U8')\n",
    "\n",
    "# Store a representation of the state rewards\n",
    "env_rs = a4.getStateReward(env)\n",
    "\n",
    "if display_print:\n",
    "    # Display reward at each state\n",
    "    print('\\n--Reward Values at Each State--')\n",
    "    a4.matprint(a4.print_value(env_rs, width=size, height=size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 ms ± 13.9 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "pi_time = %timeit -o a4.policy_iteration(env, epsilon=epsilon, gamma=gamma, max_iter=max_iter, report=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy iteration converged after  19 epochs\n",
      "-0.9907  -0.9884  -0.9855  -0.9819  -0.9773  -0.9717       -5       -5  -0.9447  -0.9308  -0.9135  -0.9308  -0.9447  -0.9557  -0.9646  -0.9717  \n",
      "-0.9884  -0.9855  -0.9819  -0.9773       -5  -0.9646  -0.9557       -5  -0.9308  -0.9135  -0.8919  -0.9135  -0.9308  -0.9447       -5  -0.9646  \n",
      "-0.9907       -5  -0.9773  -0.9717  -0.9646  -0.9557  -0.9447       -5  -0.9135       -5  -0.8649       -5  -0.9135  -0.9308  -0.9447  -0.9557  \n",
      "     -5  -0.9773  -0.9717       -5  -0.9557  -0.9447  -0.9308  -0.9135  -0.8919  -0.8649  -0.8311  -0.8649  -0.8919       -5  -0.9557       -5  \n",
      "-0.9773       -5  -0.9646  -0.9557  -0.9447  -0.9308       -5       -5  -0.8649  -0.8311  -0.7889       -5       -5       -1       -5       -1  \n",
      "-0.9717       -5  -0.9557  -0.9447       -5  -0.9135       -5  -0.8649  -0.8311  -0.7889  -0.7361       -5       -1       -1       -1       -1  \n",
      "-0.9646  -0.9557       -5  -0.9308  -0.9135  -0.8919  -0.8649       -5  -0.7889  -0.7361  -0.6701       -5       -5       -5       -5       -1  \n",
      "     -5  -0.9447       -5  -0.9135  -0.8919  -0.8649  -0.8311  -0.7889  -0.7361  -0.6701  -0.5877  -0.4846  -0.3558  -0.1947  -0.3558       -5  \n",
      "-0.9447  -0.9308  -0.9135  -0.8919  -0.8649  -0.8311  -0.7889  -0.7361  -0.6701       -5  -0.4846  -0.3558  -0.1947   0.0066       -5       -1  \n",
      "-0.9308  -0.9135  -0.8919  -0.8649  -0.8311  -0.7889       -5       -5  -0.5877       -5  -0.3558  -0.1947   0.0066   0.2583   0.5729       -5  \n",
      "-0.9447  -0.9308       -5  -0.8311  -0.7889  -0.7361  -0.6701  -0.5877  -0.4846       -5  -0.1947  -0.3558  -0.1947       -5   0.9661   1.4576  \n",
      "-0.9557  -0.9447  -0.9557       -5       -5  -0.7889       -5  -0.4846  -0.3558  -0.1947   0.0066  -0.1947       -5   0.9661   1.4576    2.072  \n",
      "-0.9646  -0.9557  -0.9646  -0.9717  -0.9773       -5  -0.4846       -5  -0.1947   0.0066   0.2583   0.0066       -5   1.4576    2.072     2.84  \n",
      "     -5       -5       -5       -5       -5  -0.4846  -0.3558  -0.1947       -5   0.2583   0.5729       -5   1.4576    2.072     2.84      3.8  \n",
      "     -1       -5       -1       -1       -5  -0.3558  -0.1947   0.0066   0.2583   0.5729   0.9661   1.4576    2.072     2.84      3.8        5  \n",
      "     -1       -1       -5       -1       -5       -5  -0.3558  -0.1947       -5   0.9661   1.4576    2.072     2.84      3.8        5        5  \n",
      "↓  ↓  ↓  ↓  →  ↓  ←  ←  →  ↓  ↓  ←  ←  ←  ←  ←  \n",
      "→  →  ↓  ↓  ←  ↓  ↓  ←  ↓  →  ↓  ←  ←  ←  ←  ↓  \n",
      "↑  ←  ↓  →  ↓  ↓  ↓  ←  ↓  ←  ↓  ←  ↓  ←  ←  ←  \n",
      "←  →  ↓  ←  ↓  ↓  →  →  ↓  ↓  ↓  ←  ←  ←  ↑  ←  \n",
      "↓  ←  →  →  →  ↓  ←  ←  ↓  ↓  ↓  ←  ←  ↓  ←  ↓  \n",
      "↓  ←  →  ↓  ←  ↓  ←  →  ↓  →  ↓  ←  →  ←  →  →  \n",
      "→  ↓  ←  ↓  ↓  ↓  ↓  ←  ↓  ↓  ↓  ←  ←  ←  ←  ↑  \n",
      "←  ↓  ←  ↓  ↓  ↓  ↓  ↓  ↓  →  ↓  ↓  ↓  ↓  ←  ←  \n",
      "↓  ↓  ↓  ↓  ↓  ↓  →  →  ↓  ←  →  ↓  ↓  ↓  ←  →  \n",
      "→  →  →  ↓  ↓  ↓  ←  ←  ↓  ←  ↓  →  →  →  ↓  ←  \n",
      "→  ↑  ←  →  →  →  →  ↓  ↓  ←  ↓  ↓  ↑  ←  ↓  ↓  \n",
      "→  ↑  ←  ←  ←  ↑  ←  →  ↓  ↓  ↓  ↓  ←  ↓  ↓  ↓  \n",
      "→  ↑  ←  ←  ←  ←  ↓  ←  →  ↓  ↓  ←  ←  ↓  ↓  ↓  \n",
      "←  ←  ←  ←  ←  ↓  ↓  ↓  ←  →  ↓  ←  ↓  ↓  ↓  ↓  \n",
      "←  ←  →  ←  ←  →  →  →  →  →  ↓  ↓  ↓  ↓  ↓  ↓  \n",
      "←  ←  ←  ↓  ←  ←  →  ↑  ←  →  →  →  →  →  →  ←  \n"
     ]
    }
   ],
   "source": [
    "pi_V, pi_policy, pi_epochs = a4.policy_iteration(env, epsilon=epsilon, gamma=gamma, max_iter=max_iter, report=True)\n",
    "\n",
    "\n",
    "\n",
    "pi_policy_arrows = a4.print_policy(pi_policy, width=size, height=size)\n",
    "\n",
    "if display_print:\n",
    "    # Display values\n",
    "    a4.matprint(a4.print_value(pi_V, width=size, height=size))\n",
    "\n",
    "    # Display policy\n",
    "    a4.matprint(pi_policy_arrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 ms ± 10.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "vi_time = %timeit -o a4.valueIteration(env, epsilon=epsilon, gamma=gamma, max_iter=max_iter, report=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value iteration converged after  97 epochs\n",
      "-0.9907  -0.9884  -0.9855  -0.9819  -0.9773  -0.9717       -5       -5  -0.9447  -0.9308  -0.9135  -0.9308  -0.9447  -0.9557  -0.9646  -0.9717  \n",
      "-0.9884  -0.9855  -0.9819  -0.9773       -5  -0.9646  -0.9557       -5  -0.9308  -0.9135  -0.8919  -0.9135  -0.9308  -0.9447       -5  -0.9646  \n",
      "-0.9907       -5  -0.9773  -0.9717  -0.9646  -0.9557  -0.9447       -5  -0.9135       -5  -0.8649       -5  -0.9135  -0.9308  -0.9447  -0.9557  \n",
      "     -5  -0.9773  -0.9717       -5  -0.9557  -0.9447  -0.9308  -0.9135  -0.8919  -0.8649  -0.8311  -0.8649  -0.8919       -5  -0.9557       -5  \n",
      "-0.9773       -5  -0.9646  -0.9557  -0.9447  -0.9308       -5       -5  -0.8649  -0.8311  -0.7889       -5       -5       -1       -5       -1  \n",
      "-0.9717       -5  -0.9557  -0.9447       -5  -0.9135       -5  -0.8649  -0.8311  -0.7889  -0.7361       -5       -1       -1       -1       -1  \n",
      "-0.9646  -0.9557       -5  -0.9308  -0.9135  -0.8919  -0.8649       -5  -0.7889  -0.7361  -0.6701       -5       -5       -5       -5       -1  \n",
      "     -5  -0.9447       -5  -0.9135  -0.8919  -0.8649  -0.8311  -0.7889  -0.7361  -0.6701  -0.5877  -0.4846  -0.3558  -0.1947  -0.3558       -5  \n",
      "-0.9447  -0.9308  -0.9135  -0.8919  -0.8649  -0.8311  -0.7889  -0.7361  -0.6701       -5  -0.4846  -0.3558  -0.1947   0.0066       -5       -1  \n",
      "-0.9308  -0.9135  -0.8919  -0.8649  -0.8311  -0.7889       -5       -5  -0.5877       -5  -0.3558  -0.1947   0.0066   0.2583   0.5729       -5  \n",
      "-0.9447  -0.9308       -5  -0.8311  -0.7889  -0.7361  -0.6701  -0.5877  -0.4846       -5  -0.1947  -0.3558  -0.1947       -5   0.9661   1.4576  \n",
      "-0.9557  -0.9447  -0.9557       -5       -5  -0.7889       -5  -0.4846  -0.3558  -0.1947   0.0066  -0.1947       -5   0.9661   1.4576    2.072  \n",
      "-0.9646  -0.9557  -0.9646  -0.9717  -0.9773       -5  -0.4846       -5  -0.1947   0.0066   0.2583   0.0066       -5   1.4576    2.072     2.84  \n",
      "     -5       -5       -5       -5       -5  -0.4846  -0.3558  -0.1947       -5   0.2583   0.5729       -5   1.4576    2.072     2.84      3.8  \n",
      "     -1       -5       -1       -1       -5  -0.3558  -0.1947   0.0066   0.2583   0.5729   0.9661   1.4576    2.072     2.84      3.8        5  \n",
      "     -1       -1       -5       -1       -5       -5  -0.3558  -0.1947       -5   0.9661   1.4576    2.072     2.84      3.8        5        5  \n",
      "↓  ↓  ↓  ↓  →  ↓  ←  ←  ↓  ↓  ↓  ↓  ↓  ↓  ←  ↓  \n",
      "→  →  ↓  ↓  ←  ↓  ↓  ←  ↓  →  ↓  ←  ↓  ↓  ←  ↓  \n",
      "↑  ←  ↓  →  ↓  ↓  ↓  ←  ↓  ←  ↓  ←  ↓  ←  ←  ←  \n",
      "←  →  ↓  ←  ↓  ↓  →  →  ↓  ↓  ↓  ←  ←  ←  ↑  ←  \n",
      "↓  ←  ↓  ↓  →  ↓  ←  ←  ↓  ↓  ↓  ←  ←  ↓  ←  ↓  \n",
      "↓  ←  →  ↓  ←  ↓  ←  →  ↓  ↓  ↓  ←  →  ←  ←  ←  \n",
      "→  ↓  ←  ↓  ↓  ↓  ↓  ←  ↓  ↓  ↓  ←  ←  ←  ←  →  \n",
      "←  ↓  ←  ↓  ↓  ↓  ↓  ↓  ↓  →  ↓  ↓  ↓  ↓  ←  ←  \n",
      "↓  ↓  ↓  ↓  ↓  ↓  →  →  ↓  ←  ↓  ↓  ↓  ↓  ←  →  \n",
      "→  →  →  ↓  ↓  ↓  ←  ←  ↓  ←  ↓  →  →  →  ↓  ←  \n",
      "→  ↑  ←  →  →  →  →  ↓  ↓  ←  ↓  ↓  ↑  ←  ↓  ↓  \n",
      "→  ↑  ←  ←  ←  ↑  ←  →  ↓  ↓  ↓  ↓  ←  ↓  ↓  ↓  \n",
      "→  ↑  ←  ←  ←  ←  ↓  ←  →  ↓  ↓  ←  ←  ↓  ↓  ↓  \n",
      "←  ←  ←  ←  ←  ↓  ↓  ↓  ←  ↓  ↓  ←  ↓  ↓  ↓  ↓  \n",
      "←  ←  →  ←  ←  →  →  →  →  ↓  ↓  ↓  ↓  ↓  ↓  ↓  \n",
      "←  ←  ←  ↓  ←  ←  →  ↑  ←  →  →  →  →  →  →  ←  \n"
     ]
    }
   ],
   "source": [
    "vi_V, vi_epochs = a4.valueIteration(env, epsilon=epsilon, gamma=gamma, max_iter=max_iter, report=True)\n",
    "\n",
    "\n",
    "\n",
    "vi_policy = a4.value_to_policy(env, V=vi_V, gamma=gamma)\n",
    "\n",
    "vi_policy_arrows = a4.print_policy(vi_policy, width=size, height=size)\n",
    "\n",
    "if display_print:\n",
    "    # display value function:\n",
    "    a4.matprint(a4.print_value(vi_V, width=size, height=size))\n",
    "    # display policy\n",
    "    a4.matprint(vi_policy_arrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.68 ms ± 568 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "Q_time = %timeit -o a4.Qlearning(env, qepsilon, lr, qgamma, episodes=10000, initial=initial, decay=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Q with all options--\n",
      " 0.273189  0.603993  -0.769452   0.135425  \n",
      "-0.821506     -1.56  -0.686167  -0.738509  \n",
      "-0.621164  0.299704  -0.602921  -0.533545  \n",
      " -0.61056    -1.872  -0.602614  -0.602614  \n",
      " 0.143375  0.846311    -1.9344  -0.571587  \n",
      "       -1        -1         -1         -1  \n",
      "    -1.56   1.18565      -1.56  -0.573727  \n",
      "       -1        -1         -1         -1  \n",
      "-0.461056     -1.56    1.10138  -0.507187  \n",
      "-0.428196   1.36987      -0.32     -1.872  \n",
      "-0.470784   1.64941      -1.56      -0.16  \n",
      "       -1        -1         -1         -1  \n",
      "       -1        -1         -1         -1  \n",
      "   -1.872   -0.3136     1.6525   0.824785  \n",
      "    -0.16     -0.16       1.95    1.08416  \n",
      "        1         1          1          1  \n",
      "\n",
      "--argmax(Q) in grid order--\n",
      " 0.604  -0.6862  0.2997  -0.6026  \n",
      "0.8463       -1  1.1856       -1  \n",
      "1.1014   1.3699  1.6494       -1  \n",
      "    -1   1.6525    1.95        1  \n",
      "\n",
      "--Policy Matrix--\n",
      "↓  →  ↓  →  \n",
      "↓  ←  ↓  ←  \n",
      "→  ↓  ↓  ←  \n",
      "←  →  →  ←  \n"
     ]
    }
   ],
   "source": [
    "Q, Q_epochs = a4.Qlearning(env, qepsilon, lr, qgamma, episodes)\n",
    "\n",
    "maxQ = np.max(Q,axis=1)\n",
    "\n",
    "Q_policy = a4.Q_to_policy(Q)\n",
    "\n",
    "Q_policy_arrows = a4.print_policy(Q_policy, width=size, height=size)\n",
    "\n",
    "if display_print: \n",
    "    print('--Q with all options--')\n",
    "    a4.matprint(Q)\n",
    "    print('\\n--argmax(Q) in grid order--')\n",
    "    a4.matprint(a4.print_value(maxQ, width=size, height=size))\n",
    "    print('\\n--Policy Matrix--')\n",
    "    a4.matprint(Q_policy_arrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default rewards in OpenAI gym Frozen-Lake-v0 are 1 for the G(oal) and 0 for everything else.\n",
    "\n",
    "Maps are drawn according to the following logic\n",
    "\n",
    "```\n",
    "if desc and map_name are None, \n",
    "   then a default random map is drawn with 8\n",
    "        using frozen_lake.generate_random_map(size=8, p=0.8)\n",
    "elif desc is None and a map_name is given\n",
    "   then a map_name is either '4x4' or '8x8'\n",
    "        and is drawn from the dict MAPS in frozen_lake.py\n",
    "elif desc is given\n",
    "   then it must be in the form of a list with \n",
    "```\n",
    "\n",
    "Default action probabilities are 1/3 chosen action, 1/3 each for right angles to chosen action, and 0 for reverse of chosen action. This is set with `is_slippery=True`. If `is_slippery=False`, then P=1 for chosen action and 0 for all other actions.\n",
    "\n",
    "|ACTION|Value|Symbol|\n",
    "|------|-----|------|\n",
    "|LEFT  | 0   | ←    |\n",
    "|DOWN  | 1   | ↓    |\n",
    "|RIGHT | 2   | →    |\n",
    "|UP    | 3   | ↑    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Environment: <https://gym.openai.com/envs/FrozenLake-v0/>\n",
    "- Code: <https://github.com/Twice22/HandsOnRL>\n",
    "- Tutorial: <https://twice22.github.io/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'rH': [rH], \n",
    "                        'rG': [rG], \n",
    "                        'rF': [rF], \n",
    "                        'size': [size], \n",
    "                        'p': [p], \n",
    "                        'desc': [desc], \n",
    "                        'map_name': [map_name],                        \n",
    "                        'is_slippery': [is_slippery],\n",
    "                        'epsilon': [epsilon],\n",
    "                        'gamma': [gamma], \n",
    "                        'max_iter': [max_iter], \n",
    "                        'qepsilon': [qepsilon], \n",
    "                        'lr': [lr], \n",
    "                        'qgamma': [qgamma], \n",
    "                        'episodes': [episodes], \n",
    "                        'initial': [initial],\n",
    "                        'env_desc': [env_desc],\n",
    "                        'env_rs': [env_rs],\n",
    "                        'pi_time': [pi_time.average],\n",
    "                        'pi_V': [pi_V],\n",
    "                        'pi_epochs': [pi_epochs],\n",
    "                        'pi_policy': [pi_policy],\n",
    "                        'pi_policy_arrows': [pi_policy_arrows],\n",
    "                        'vi_time': [vi_time.average],\n",
    "                        'vi_V': [vi_V],\n",
    "                        'vi_epochs': [vi_epochs],\n",
    "                        'vi_policy': [vi_policy],\n",
    "                        'vi_policy_arrows': [vi_policy_arrows],\n",
    "                        'Q_time': [Q_time.average],\n",
    "                        'Q': [Q],\n",
    "                        'Q_epochs': [Q_epochs],\n",
    "                        'Q_V': [maxQ],\n",
    "                        'Q_policy': [Q_policy],\n",
    "                        'Q_policy_arrows': [Q_policy_arrows]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rH</th>\n",
       "      <th>rG</th>\n",
       "      <th>rF</th>\n",
       "      <th>size</th>\n",
       "      <th>p</th>\n",
       "      <th>desc</th>\n",
       "      <th>map_name</th>\n",
       "      <th>is_slippery</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>gamma</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>qepsilon</th>\n",
       "      <th>lr</th>\n",
       "      <th>qgamma</th>\n",
       "      <th>episodes</th>\n",
       "      <th>initial</th>\n",
       "      <th>env_desc</th>\n",
       "      <th>env_rs</th>\n",
       "      <th>pi_time</th>\n",
       "      <th>pi_V</th>\n",
       "      <th>pi_epochs</th>\n",
       "      <th>pi_policy</th>\n",
       "      <th>pi_policy_arrows</th>\n",
       "      <th>vi_time</th>\n",
       "      <th>vi_V</th>\n",
       "      <th>vi_epochs</th>\n",
       "      <th>vi_policy</th>\n",
       "      <th>vi_policy_arrows</th>\n",
       "      <th>Q_time</th>\n",
       "      <th>Q</th>\n",
       "      <th>Q_V</th>\n",
       "      <th>Q_policy</th>\n",
       "      <th>Q_policy_arrows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[SFFFFFHHFFFFFFFF, FFFFHFFHFFFFFFHF, FHFFFFFHF...</td>\n",
       "      <td>16x16</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>[[S, F, F, F, F, F, H, H, F, F, F, F, F, F, F,...</td>\n",
       "      <td>[-0.2, -0.2, -0.2, -0.2, -0.2, -0.2, -1.0, -1....</td>\n",
       "      <td>0.116077</td>\n",
       "      <td>[-0.99071544970536, -0.9883943121316999, -0.98...</td>\n",
       "      <td>19</td>\n",
       "      <td>[1, 1, 1, 1, 2, 1, 0, 0, 2, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[↓, ↓, ↓, ↓, →, ↓, ←, ←, →, ↓, ↓, ←, ←, ←, ←,...</td>\n",
       "      <td>0.112625</td>\n",
       "      <td>[-0.9907154521919761, -0.9883943146183161, -0....</td>\n",
       "      <td>97</td>\n",
       "      <td>[1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[[↓, ↓, ↓, ↓, →, ↓, ←, ←, ↓, ↓, ↓, ↓, ↓, ↓, ←,...</td>\n",
       "      <td>0.130254</td>\n",
       "      <td>[[-2.206321221746009, -2.1498576191789085, -2....</td>\n",
       "      <td>[-2.1498576191789085, -2.052499462302082, -1.9...</td>\n",
       "      <td>[1, 1, 2, 2, 3, 1, 0, 0, 2, 1, 3, 2, 2, 3, 0, ...</td>\n",
       "      <td>[[↓, ↓, →, →, ↑, ↓, ←, ←, →, ↓, ↑, →, →, ↑, ←,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rH  rG   rF  size    p                                               desc  \\\n",
       "0  -1   1 -0.2    16  0.8  [SFFFFFHHFFFFFFFF, FFFFHFFHFFFFFFHF, FHFFFFFHF...   \n",
       "\n",
       "  map_name  is_slippery       epsilon  gamma  max_iter  qepsilon   lr  qgamma  \\\n",
       "0    16x16        False  1.000000e-08    0.8     10000       0.1  0.8    0.95   \n",
       "\n",
       "   episodes  initial                                           env_desc  \\\n",
       "0     10000        0  [[S, F, F, F, F, F, H, H, F, F, F, F, F, F, F,...   \n",
       "\n",
       "                                              env_rs   pi_time  \\\n",
       "0  [-0.2, -0.2, -0.2, -0.2, -0.2, -0.2, -1.0, -1....  0.116077   \n",
       "\n",
       "                                                pi_V  pi_epochs  \\\n",
       "0  [-0.99071544970536, -0.9883943121316999, -0.98...         19   \n",
       "\n",
       "                                           pi_policy  \\\n",
       "0  [1, 1, 1, 1, 2, 1, 0, 0, 2, 1, 1, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    pi_policy_arrows   vi_time  \\\n",
       "0  [[↓, ↓, ↓, ↓, →, ↓, ←, ←, →, ↓, ↓, ←, ←, ←, ←,...  0.112625   \n",
       "\n",
       "                                                vi_V  vi_epochs  \\\n",
       "0  [-0.9907154521919761, -0.9883943146183161, -0....         97   \n",
       "\n",
       "                                           vi_policy  \\\n",
       "0  [1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, ...   \n",
       "\n",
       "                                    vi_policy_arrows    Q_time  \\\n",
       "0  [[↓, ↓, ↓, ↓, →, ↓, ←, ←, ↓, ↓, ↓, ↓, ↓, ↓, ←,...  0.130254   \n",
       "\n",
       "                                                   Q  \\\n",
       "0  [[-2.206321221746009, -2.1498576191789085, -2....   \n",
       "\n",
       "                                                 Q_V  \\\n",
       "0  [-2.1498576191789085, -2.052499462302082, -1.9...   \n",
       "\n",
       "                                            Q_policy  \\\n",
       "0  [1, 1, 2, 2, 3, 1, 0, 0, 2, 1, 3, 2, 2, 3, 0, ...   \n",
       "\n",
       "                                     Q_policy_arrows  \n",
       "0  [[↓, ↓, →, →, ↑, ↓, ←, ←, →, ↓, ↑, →, →, ↑, ←,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if display_print: \n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save DataFrame to Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the cells below to save the results of running this notebook to an HDF5 table.\n",
    "\n",
    "I've commented them out to avoid contaminating the results saved from the `iterate` version of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "# try:\n",
    "#     dataset = pd.read_hdf('data.h5', key='dataset', mode='a')\n",
    "# except FileNotFoundError:\n",
    "#     results.to_hdf('data.h5', key='dataset', mode='a')\n",
    "# else:\n",
    "#     dataset.append(\n",
    "#         other=results, \n",
    "#         ignore_index=True\n",
    "#         ).to_hdf(\n",
    "#         path_or_buf='data.h5', \n",
    "#         key='dataset', \n",
    "#         mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if display_print:\n",
    "#     pd.read_hdf('data.h5', key='dataset', mode='a')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
